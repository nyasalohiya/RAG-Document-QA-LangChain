{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Based PDF Question Answering System"
      ],
      "metadata": {
        "id": "BLJh_QNPn3SR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Dependencies\n",
        "## Step 2: Import Libraries\n",
        "## Step 3: Load PDF\n",
        "## Step 4: Split into Chunks\n",
        "## Step 5: Create Embeddings\n",
        "## Step 6: Store in ChromaDB\n",
        "## Step 7: Create Retriever\n",
        "## Step 8: Load LLM\n",
        "## Step 9: Ask Questions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4gewEAAfn7kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dependencies"
      ],
      "metadata": {
        "id": "mhVEKgfChN-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2Y6cXx2nhGHH"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-community chromadb pypdf sentence-transformers transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libraries"
      ],
      "metadata": {
        "id": "YA8-TGBThS6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "KQ03500chWD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "file loading"
      ],
      "metadata": {
        "id": "TTgHtcz-hicU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "JtAkiYnzhfNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"AML FINAL NOTES.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(\"Total Pages:\", len(docs))\n",
        "print(\"\\nSample Content:\\n\")\n",
        "print(docs[0].page_content[:300])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "No1KyGdthYIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting into chunks"
      ],
      "metadata": {
        "id": "ymikE4L5hlLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=150\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "print(\"Total Chunks:\", len(chunks))"
      ],
      "metadata": {
        "id": "Lz0EdioAhnS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "id": "028piAPQhr8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_function = SentenceTransformerEmbeddings(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wAFuiw_nhq4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create vector db"
      ],
      "metadata": {
        "id": "7Rz6YR91h4rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = \"db\"\n",
        "\n",
        "vdb = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embedding_function,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "vdb.persist()\n",
        "\n",
        "print(\"Vector DB Created Successfully\")"
      ],
      "metadata": {
        "id": "a4hjr4Lph7f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create retriever"
      ],
      "metadata": {
        "id": "FWzAVX8vh93V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vdb.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "ejzO0zKeiA9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading llm"
      ],
      "metadata": {
        "id": "cyRqGL5LiEIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    max_new_tokens=256,\n",
        "    max_length=None\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "IzJpcKadiFaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "rag query"
      ],
      "metadata": {
        "id": "6rYRpJ4miHFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the final clusters in the K-means example?\"\n",
        "\n",
        "retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Answer the question based only on the context below:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "response = llm.invoke(prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7i5xklISiIMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#some more questions\n",
        "\n",
        "\n",
        "query = \"which algorithm in this document use distance calculations?\"\n",
        "\n",
        "retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Answer the question based only on the context below:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "response = llm.invoke(prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TigdZNHolOs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#some more questions\n",
        "\n",
        "\n",
        "query = \"which Clustering methods are explained in the document\"\n",
        "\n",
        "retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Answer the question based only on the context below:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "response = llm.invoke(prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WmDjki5_l1C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c9_3jBsnnEwf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}